---
title: "Level 300: Optimize Data Pattern using Redshift Data Sharing"
menutitle: "Optimize Data Pattern using Redshift Data Sharing"
date: 2020-11-18T09:00:08-04:00
chapter: false
weight: 1
hidden: false
---
## Author

- **Raman Pujani**, Solutions Architect.

## Introduction

Optimize workload placement, and optimize your architecture for user, software, data, hardware, and development and deployment patterns to increase energy efficiency. Each of these areas represents opportunities to employ best practices to reduce the sustainability impact of your cloud workload by maximizing utilization, and minimizing waste and the total resources deployed and powered to support your workload.

AWS Well-Architected Sustainability Pillar provides best practices for six areas - region selection, user behavior pattern, software and architecture pattern, data pattern, hardware pattern, and development & deployment process. This lab focuses on Data patterns, specifically focused on removing unneeded or redundant date, and minimizing data movement across networks.

## Goals
At the end of this lab you will:

* Understand how to identify optimization areas using AWS Well-Architected Sustainability Pillar best practices
* Baseline and optimize workload by identifying Sustainability KPIs
* Learn how to use Amazon Redshift Data Sharing feature to implement few Data Patterns best practices described in Sustainability Pillar

## Prerequisites

* The lab is designed to run in your own AWS account
* You can launch Redshift cluster in us-east-1 and us-west-1 regions using ra3 nodes
* You can create S3 bucket in your AWS account

{{% notice note %}}
**NOTE:** You will be billed for any applicable AWS resources used if you complete this lab that are not covered in the [AWS Free Tier](https://aws.amazon.com/free/).
When you decide to stop the lab at any point in time, please revisit the [clean up]({{< ref "content/Sustainability/300_Labs/300_cur_reports_as_efficiency_reports/cleanup.md" >}}) instructions at the end so you stop incuring cost (e.g. for storage in Amazon S3).
{{% /notice %}}

## Workload details
The use case is AnyCompany (an event management organization) running a central data warehouse environment on AWS Redshift in east region, which is used by various departments in the organization for their respective storage, analytical processing, and reporting. Marketing department is the top consumer of the data warehouse, and have data engineers, analysts, and scientists based out of US west coast. Marketing team has implemented their own Redshift cluster in AWS west region, which refreshes nightly using Redshift snapshot received from AWS east (producer) and uploading in AWS west (consumer) region Redshift cluster. Since Marketing team analytical processing consumes lots of resources & integrated with their west coast based on-premise hosted downstream applications, they perform their analytical processing in west region, and other departments use east region hosted data warehouse. This requires storing redundant dataset in west region, and transferring huge amount of data (via nightly ETL feed) over network between AWS regions. This is not a Sustainability friendly implementation, and can be optimized using AWS WA Sustainability Pillar best practices for Data patterns. Also, with this approach, the insights generated by the Marketing department are not based on live data.

## Workload optimization for Sustainability
In this case, optimization areas include:
* Marketing team using only dataset which is required for their analytical processing, whereas currently they use full dataset. This reduces storage requirements in west coast. 
* by reducing the amount of data copy between east and west region, this reduces network traffic as well. AWS services help optimize the workload to make sustainability impact.

## Technical solution
By introducing Amazon Redshift Data Sharing feature, Marketing department can optimize their implementation to make Sustainability impact, and avoid redundant storage & reduce data transfer over network between AWS regions. Data sharing enables instant, granular, and fast data access across Amazon Redshift clusters without the need to copy or move it. With data sharing, you have live access to data, so that your users can see the most up-to-date and consistent information as it's updated in Amazon Redshift clusters, and provides cost benefit.

## Sustainability Improvement Process
The goals of your improvement process can be:
* To eliminate waste, low utilization, and idle or unused resources
* To maximize the value from resources you consume

This lab use case focuses on removing unneeded or redundant date, and minimizing data movement across network. For more details, refer to [User Guide](https://docs.aws.amazon.com/wellarchitected/latest/sustainability-pillar/improvement-process.html) which explains iterative process that evaluates, prioritizes, tests, and deploys sustainability-focused improvements for cloud workloads.

To evaluate specific improvements, understand the resources provisioned by your workload to complete a unit of work. Evaluate potential improvements, and estimate their potential impact, the cost to implement, and the associated risks. To measure improvements over time, first understand what you have provisioned in AWS and how those resources are being consumed.

Refer to [User Guide](https://docs.aws.amazon.com/wellarchitected/latest/sustainability-pillar/evaluate-specific-improvements.html) for detailed understanding around evaluating specific improvements. At high level:
* Use your proxy metrics to measure the resources provisioned to achieve business outcomes.

  ![Proxy Metrics](/Sustainability/300_optimize_data_pattern_using_redshift_data_sharing/lab-0/images/proxy_metrics_type.png?classes=lab_picture_small)

  For this lab, we will use below proxy metrics (provisioned resources):
    * Total data storage used (MB provisioned)
    * Total data transfer over network (MB transferred)

* Select business metrics to quantify the achievement of business outcomes. Your business metrics should reflect the value provided by your workload, for example, the number of simultaneous active users, API calls served, or the number of transactions completed. For this lab, we will use total number of events held (business outcome) as business metric.

* To calculate Sustainability Key Performance Indicator (KPI), we will use the following formula, divide the provisioned resources by the business outcomes achieved to determine the provisioned resources per unit of work:

    ![Sustainability KPI](/Sustainability/300_optimize_data_pattern_using_redshift_data_sharing/lab-0/images/sustainability_kpi2.png?classes=lab_picture_small)

  Our improvement goal is to:
  * Reduce total storage used, and data transfer over network for all events
  * Reduce per event provisioned resources


{{< prev_next_button link_next_url="./1_understand_data_sharing/" button_next_text="Start Lab" first_step="true" />}}

## Steps:
{{% children  %}}
